{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "m4Fwf3gvo8Xq"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# getting the activation function for the hidden layer\n",
        "\n",
        "def hyper_tan(h):\n",
        "  print(\"tanh \", np.tanh(h).shape)\n",
        "  return np.tanh(h)"
      ],
      "metadata": {
        "id": "toDLeXoDoxh2"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# getting the activation function of the output layer\n",
        "\n",
        "def sigmoid(h):\n",
        "  print(\"sigmoid \", np.exp(-h).shape)\n",
        "  return 1/(1 + np.exp(-h))"
      ],
      "metadata": {
        "id": "e17Xhgs-nwEc"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid_derivative(yhat):\n",
        "  print(\"Sigmoid derivative \", (yhat * (1 - yhat)).shape)\n",
        "  return yhat * (1 - yhat)"
      ],
      "metadata": {
        "id": "cRjaJ5KydX_m"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def binary_cross_entropy(y_pred, y):\n",
        "  print(\"BCED\", (y * np.log(y_pred) + (1 - y) * np.log(1 - y_pred)).shape)\n",
        "  return (-(y * np.log(y_pred) + (1 - y) * np.log(1 - y_pred)))"
      ],
      "metadata": {
        "id": "vBnPFflRnlCO"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.log(1 - pred_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHa40WOfpF0u",
        "outputId": "860e515f-0bba-4716-dd6e-72d1d5334590"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.49625226],\n",
              "       [-1.8747512 ],\n",
              "       [-1.98322166],\n",
              "       [-2.25912019]])"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def binary_cross_entropy_derivative(y, y_pred):\n",
        "  print(\"BCED \", ((y_pred - y) / (y_pred * (1 - y_pred))).shape)\n",
        "  return (y_pred - y) / (y_pred * (1 - y_pred))"
      ],
      "metadata": {
        "id": "Qpl4PV80gL7V"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #Initializing the weight matrix\n",
        "\n",
        "# def params():\n",
        "\n",
        "#   W1 = np.random.rand(2,2)\n",
        "#   b1 = np.random.rand(2,1)\n",
        "#   W2 = np.random.rand(2,1)\n",
        "#   b2 = np.random.rand(1,1)\n",
        "\n",
        "#   return W1, b1, W2, b2"
      ],
      "metadata": {
        "id": "BQf2afEyoxfC"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        "y = np.array([[0],[1],[1],[0]])"
      ],
      "metadata": {
        "id": "4YKgOpHxdvIG"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmn3NimtyU28",
        "outputId": "7a1945f7-4f40-42c9-80f4-ef54736f41f7"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10000\n",
        "lr = 0.001"
      ],
      "metadata": {
        "id": "FWbfkXaRkpk7"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W1 = np.random.rand(2,2)\n",
        "b1 = np.random.rand(1,2)\n",
        "W2 = np.random.rand(2,1)\n",
        "b2 = np.random.rand(1,1)"
      ],
      "metadata": {
        "id": "iohV2YenkqhG"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Initial hidden weights: \",end='')\n",
        "print(*W1)\n",
        "print(\"Initial hidden biases: \",end='')\n",
        "print(*b1)\n",
        "print(\"Initial output weights: \",end='')\n",
        "print(*W2)\n",
        "print(\"Initial output biases: \",end='')\n",
        "print(*b2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svwQAKTZkrYc",
        "outputId": "e1b1b469-0470-4602-b068-0ee098b91049"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial hidden weights: [0.93103698 0.25031844] [0.81387328 0.01137922]\n",
            "Initial hidden biases: [0.81444856 0.15560155]\n",
            "Initial output weights: [0.21222728] [0.33907519]\n",
            "Initial output biases: [0.81258586]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = np.array([1, 1, 0]).reshape(-1, 1).shape"
      ],
      "metadata": {
        "id": "7bCy69qLqdvk"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
        "y_pred.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXQblm92qfHL",
        "outputId": "91581087-dc8a-4bcb-bac9-15dcb41abf60"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2,)"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_35QAjzfqfsM"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Nn2BAmb8qfz2"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l8LNbK_Rqf7D"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BV8fPq8MqgB2"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in range(epochs):\n",
        "  #Forward Propagation\n",
        "  # hidden_layer_activation = np.dot(inputs,hidden_weights)\n",
        "  # hidden_layer_activation += hidden_bias\n",
        "  # hidden_layer_output = sigmoid(hidden_layer_activation)\n",
        "\n",
        "  h1 = np.dot(X, W1) + b1 #first get the dot product of the weight matrix and the input\n",
        "  print(\"h1 \", h1.shape)\n",
        "  a1 = hyper_tan(h1)  #apply activation function on the value of h1\n",
        "  print(\"a1 \", a1.shape)\n",
        "\n",
        "  # output_layer_activation = np.dot(hidden_layer_output,output_weights)\n",
        "  # output_layer_activation += output_bias\n",
        "  # predicted_output = sigmoid(output_layer_activation)\n",
        "\n",
        "  h2 = np.dot(a1, W2) + b2 #getting the unactivated value of output layer\n",
        "  print(\"h2 \", h2.shape)\n",
        "  pred_output = sigmoid(h2) #final predicted output of the neural network\n",
        "  print(\"pred_output \", pred_output.shape)\n",
        "  #Backpropagation\n",
        "  \n",
        "  loss = binary_cross_entropy(pred_output, y)\n",
        "  # d_pred = loss * binary_cross_entropy_derivative(y, pred_output)\n",
        "\n",
        "  #dL/dW2\n",
        "  dW2 = binary_cross_entropy_derivative(pred_output, y) * np.dot(sigmoid_derivative(pred_output), a1)\n",
        "  print(\"dW2 \", dW2.shape)\n",
        "  W2 = W2 - lr * dW2 #updating W2\n",
        "\n",
        "  #dL/db2\n",
        "  db2 = binary_cross_entropy_derivative(y, pred_output) * sigmoid_derivative(pred_output)\n",
        "  b2 = b2 - lr * db2 #updating b2\n",
        "\n",
        "  #dL/dW1\n",
        "  dW1 = dW2 * (1 - hyper_tan(h1)) * X\n",
        "  W1 = W1 - lr * dW1 #updating W1\n",
        "\n",
        "  #dL/db1\n",
        "  db1 = dW2 * (1 - hyper_tan(h1))\n",
        "  b1 = b1 - lr * db1 #updating b1\n",
        "\n",
        "\n",
        "\n",
        "  # db2 = sigmoid_derivative(pred_output)\n",
        "\n",
        "  # # one_hot_Y = one_hot(Y)\n",
        "  # dh2 = binary_cross_entropy(pred_output, y) #implement loss function here\n",
        "  # dW2 = np.mean(dh2.dot(a1.T))\n",
        "  # db2 = np.mean(np.sum(dh2))\n",
        "  # dh1 = W2.T.dot(dh2) * ReLU_deriv(h1)\n",
        "  # dW1 = 1 / m * dh1.dot(X.T)\n",
        "  # db1 = 1 / m * np.sum(dh1)\n",
        "  \n",
        "  # # d_output = error * sigmoid_derivative(predicted_output)\n",
        "\n",
        "  # # now we have to implement gradient descent\n",
        "  # partial_W2 = -(( y / pred_output) - ((1 - y) / (1 - pred_output))) * pred_output * (i - pred_output) * \n",
        "\n",
        "  # error_hidden_layer = d_predicted_output.dot(output_weights.T)\n",
        "  # d_hidden_layer = error_hidden_layer * sigmoid_derivative(hidden_layer_output)\n",
        "\n",
        "  # #Updating Weights and Biases\n",
        "  # output_weights += hidden_layer_output.T.dot(d_predicted_output) * lr\n",
        "  # output_bias += np.sum(d_predicted_output,axis=0,keepdims=True) * lr\n",
        "  # hidden_weights += inputs.T.dot(d_hidden_layer) * lr\n",
        "  # hidden_bias += np.sum(d_hidden_layer,axis=0,keepdims=True) * lr\n",
        "\n",
        "print(\"Initial hidden weights: \",end='')\n",
        "print(*W1)\n",
        "print(\"Initial hidden biases: \",end='')\n",
        "print(*b1)\n",
        "print(\"Initial output weights: \",end='')\n",
        "print(*W2)\n",
        "print(\"Initial output biases: \",end='')\n",
        "print(*b2)\n",
        "\n",
        "print(\"\\nOutput from neural network after 10,000 epochs: \",end='')\n",
        "print(*predicted_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "LU5hPT9zkrbI",
        "outputId": "0c670b81-7c2c-4d5f-b28d-01c78ebfd6ba"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "h1  (4, 2)\n",
            "tanh  (4, 2)\n",
            "a1  (4, 2)\n",
            "h2  (4, 1)\n",
            "sigmoid  (4, 1)\n",
            "pred_output  (4, 1)\n",
            "BCED (4, 1)\n",
            "BCED  (4, 1)\n",
            "Sigmoid derivative  (4, 1)\n",
            "dW2  (4, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-98-3d79fa91104a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m   \u001b[0mdW2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbinary_cross_entropy_derivative\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msigmoid_derivative\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_output\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0ma1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dW2 \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdW2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m   \u001b[0mW2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mW2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdW2\u001b[0m \u001b[0;31m#updating W2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m   \u001b[0;31m#dL/db2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (2,1) (4,2) "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OoEnFMFzkrd3"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BSsg7Pprkrge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qb2Mc3B7kri-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JlQny9KNkrl3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wiJ-BSAEkroi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2pLkBKNSkrq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Chjy36n5krtZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "40CplP1KkrwF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d4DgYq_Tkryv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gMx_z9pEkr1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tEkRv3fBkr3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rKtBeQ5Skr6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qkHvpVilkr9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#implementing the forward propagation\n",
        "\n",
        "def forward_p(W1, b1, W2, b2):\n",
        "\n",
        "  h1 = np.dot(W1, X) + b1 #first get the dot product of the weight matrix and the input\n",
        "  a1 = hyper_tan(h1)  #apply activation function on the value of h1\n",
        "  h2 = np.dot(a1, W2) + b2 #getting the unactivated value of output layer\n",
        "  output = hyper_tan(h2) #final predicted output of the neural network\n",
        "\n"
      ],
      "metadata": {
        "id": "4H8fIBwroxkZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xReOGJDxoxnF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wxSPgcSYoxpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uPhTsVJLoxsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cz_2pi91jQGq"
      },
      "outputs": [],
      "source": [
        "class neural_net:\n",
        "  def __init__(self):\n",
        "        self.input = 4 # number of inputs\n",
        "        self.output = 1 # output units \n",
        "        self.hidden_units = 6 # single layer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W1 = np.random.rand(2,2)\n",
        "b1 = np.random.rand(1,2)\n",
        "W2 = np.random.rand(2,1)\n",
        "b2 = np.random.rand(1,1)"
      ],
      "metadata": {
        "id": "zwUebjJ3oxug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h1 = np.dot(X, W1) + b1 #first get the dot product of the weight matrix and the input\n",
        "a1 = hyper_tan(h1)  #apply activation function on the value of h1\n",
        "h2 = np.dot(a1, W2) + b2 #getting the unactivated value of output layer\n",
        "output = hyper_tan(h2) #final predicted output of the neural network"
      ],
      "metadata": {
        "id": "o2BLVpRNb4ls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h1.shape"
      ],
      "metadata": {
        "id": "ukhFH49OcPkI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a1.shape"
      ],
      "metadata": {
        "id": "Nrj3HJjocmjh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h2.shape"
      ],
      "metadata": {
        "id": "J6Kiwue2c9jk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "id": "YoYP6T1nc-1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d_predicted_output = np.random.rand(4,2)\n",
        "lr = 1"
      ],
      "metadata": {
        "id": "gPuEIgNthd5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_bias = np.sum(d_predicted_output,axis=0,keepdims=True) * lr"
      ],
      "metadata": {
        "id": "RnOKviO9dAqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_bias.shape"
      ],
      "metadata": {
        "id": "Z1j2AKbghmCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3wgzFFIKhrRg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}